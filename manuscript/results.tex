\section{Numerical simulations}
\label{sec:num_simulations}

We investigated different computational algorithms for inverting gravity disturbances and total-field anomalies. To test the capability of the fast equivalent-layer technique for processing that potential field data, we construct two tests. The first one is a measure of the computational effort by counting the number of floating-point operations (\textit{flops}), such as additions, subtractions, multiplications, and divisions \citep{golub-vanloan2013}. Secondly, we demonstrated the solution stability by using a zeroth-order Tikhonov regularization in different noise levels. Finally, we show two examples of gravity and magnetic data processing.


For all applications, we generate a model composed by two spheres (PAREI AQUI - ANDRE)
%
%%%%% Diego is writing here
\subsection{Floating-point operations calculation}

To measure the computational effort of the different algorithms to solve the equivalent layer linear system, a non-hardware dependent method can be useful because allow us to do direct comparison between them. Counting the floating-point operations (\textit{flops}), i.e., additions, subtractions, multiplications and divisions is a good way to quantify the amount of work of a given algorithm \citep{golub-vanloan2013}. For example, the number of \textit{flops} necessary to multiply two vectors $\mathbb{R}^{N}$ is $2N$. A common matrix-vector multiplication with dimension $\mathbb{R}^{N \times N}$ and $\mathbb{R}^{N}$, respectively, is $2N^2$ and a multiplication of two matrices $\mathbb{R}^{N \times N}$ is $2N^3$. Figure XX shows the total flops count for the different methods presented in this review with a crescent number of data, ranging from $10,000$ to $1,000,000$. 

\subsubsection{Normal equations using Cholesky algorithm}

\begin{equation}
	f_{classical} = \dfrac{5}{6} N^3 + 4N^2
\label{flops_classical}
\end{equation}

\subsubsection{Window method \citep{leao-silva1989}}

\begin{equation}
	f_{window} = W\dfrac{5}{6} N_w^3 + 4N_w^2
\label{flops_leao-silva}
\end{equation}

\subsubsection{PEL method \citep{oliveirajr-etal2013}}

\begin{equation}
	f_{pel} = \dfrac{1}{3} H^3 + 2H^2 + 2NN_wH + H^2N + 2HN + 2NP
\label{flops_pel}
\end{equation}

\subsubsection{Conjugate gradient least square (CGLS)}

\begin{equation}
	f_{cgls} = 2N^2 + it(4N^2 + 12N)
\label{cgls}
\end{equation}

\subsubsection{Wavelet compression method with CGLS \citep{li-oldenburg2010}}

\begin{equation}
	f_{wavelet} = 2NC_r + 4N\log_2(N) + it(4N\log_2(N) + 4NC_r + 12C_r)
\label{wavelet}
\end{equation}

\subsubsection{Convolutional equivalent layer for gravity data \citep{takahashi2020}}

This methods replaces the matrix-vector multiplication of the iterative fast-equivalent technique \citep{siqueira-etal2017} by three steps involving a Fourier transform and a inverse Fourier transform, 
and a Hadamard product of matrices. Considering that the first column of our BCCB matrix has $4N$ elements, the flops count of this method is

\begin{equation}
	f_{convgrav} = \kappa4N\log_2(4N) + it(27N + \kappa8N\log_2(4N))
\label{convgrav}
\end{equation}

In the resultant count we considered a \textit{radix-2} algorithm for the fast Fourier transform and its inverse, which has a $\kappa$ equals to 5 and requires $\kappa4N\log_2(4N)$ flops each. The Hadarmard product of two matrices of $4N$ elements with complex numbers takes $24N$ flops. Note that equation \ref{convgrav} is different from the one presented in \cite{takahashi2020convolutional} simply because we added the eigenvalues calculation in this form. It does not differentiate much in order of magnitude because the iterative part is the most costful.

\subsubsection{Convolutional equivalent layer for magnetic data \citep{takahashi2022}}

The convolutional equivalent layer for magnetic data uses the same flops count of the main operations as in the gravimetric case, the big difference is the use of the conjugate gradient algorithm to solve the inverse problem.
It requires a Hadamard product outside of the iterative loop and more matrix-vector vector-vector multiplications inside the loop as seem in equation \ref{cgls}.

\begin{equation}
	f_{convmag} = \kappa16N\log_2(4N) + 24N + it(\kappa16N\log_2(4N) + 60N)
\label{convmag}
\end{equation}

\subsubsection{Deconvolutional method}

The deconvolution method does not require an iterative algorithm, rather it solves the estimative of the physical properties in a single step using the $4N$ eigenvalues of the BCCB matrix as in the convolutional method. It requires a two fast Fourier transform ($\kappa4N\log_2(4N)$), one for the eigenvalues and another for the data transformation, a element by element division ($24N$) and finally, a fast inverse Fourier transform for the final estimative ($\kappa4N\log_2(4N)$).

\begin{equation}
	f_{deconv} = \kappa12N\log_2(4N) + 24N
	\label{deconv}
\end{equation}

Using the deconvolutional method with a Wiener stabilization adds two multiplications of complex elements of the conjugates eigenvalues ($24N$ each) and the sum of $4N$ elements with the stabilization parameter $\mu$

\begin{equation}
	f_{deconvwiener} = \kappa12N\log_2(4N) + 76N
	\label{deconvwiener}
\end{equation}

\subsection{Stability analysis}

For the stability analysis we show the comparison of the normal equations solution with zeroth-order Tikhonov regularization, the convolutional method for gravimetric and magnetic data, the deconvolutional method and the deconvolutional method with different values for the Wiener stabilization. We create $21$ data sets adding a crescent pseudo-random noise to the original data, which varies from $0\%$ to $10\%$ of the maximum anomaly value, in intervals of $0.5\%$. These noises has mean equal to zero and a Gaussian distribution.
Figure XX shows how the residual between the predicted data and the noise-free data changes as the level of the noise is increased. We can see that for all methods, a linear tendency can be observed as it is expected. The inclination of the straight line is a indicative of the stability of each method. As show in the graph the deconvolutional method is very unstable and it is really necessary to use a stabilization method to have a good parameter estimative. In contrast, a correct value of the stabilization parameter is necessary to not overshoot the smootheness of the solution as it is the case for the well-known zeroth-order Tikhonov regularization. For the example using this gravimetric data, the optimal value for the Wiener stabilization parameter is $\mu = 10^{-9}$. Figure XX shows the comparison of the predicted data for each method with the original data.

For the magnetic data, the Wiener parameter seems to have the best solution for $\mu = 10^{-13}$. Figure XX shows the comparison of the predicted data for each method with the original data.
